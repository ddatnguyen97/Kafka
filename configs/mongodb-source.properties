name=mongo-source
connector.class=com.mongodb.kafka.connect.MongoSourceConnector
tasks.max=1

# Connection and source configuration
connection.uri=mongodb://mongo1:30001,mongo2:30002,mongo3:30003/
database=
collection=

# output.format.value=schema
# output.format.key=schema
# key.converter=org.apache.kafka.connect.json.JsonConverter
# key.converter.schemas.enable=false
# key.converter.schema.registry.url= http://localhost:8081/
# value.converter=org.apache.kafka.connect.json.JsonConverter
# value.converter.schemas.enable=false
# value.converter.schema.registry.url= http://localhost:8081/


key.converter=org.apache.kafka.connect.json.JsonConverter
key.converter.schemas.enable=false
key.converter.schema.registry.url= http://schema-registry:8081/
# key.converter.enhanced.avro.schema.support=true
value.converter=org.apache.kafka.connect.json.JsonConverter
value.converter.schemas.enable=false
value.converter.schema.registry.url= http://schema-registry:8081/
# value.converter.enhanced.avro.schema.support=true

topic.prefix=
topic.suffix=
poll.max.batch.size=1000
poll.await.time.ms=5000

# Change stream options
pipeline=[]
batch.size=0
change.stream.full.document=updateLookup
publish.full.document.only=true
collation=

# transforms.copyFieldToKey.type=org.apache.kafka.connect.transforms.ValueToKey
# transforms.copyFieldToKey.fields=source
# transforms.extractKeyFromStruct.type=org.apache.kafka.connect.transforms.ExtractField$Key
# transforms.extractKeyFromStruct.field=source